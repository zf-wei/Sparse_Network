{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c95f72d-ea2a-4478-8041-319f8769d3ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T06:59:23.109660Z",
     "start_time": "2024-11-01T06:59:23.106622Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "sys.stdout.flush()\n",
    "\n",
    "# 将子目录添加到 sys.path\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(os.path.join(current_dir,'EffectiveResistanceSampling'))\n",
    "from EffectiveResistanceSampling.Network import *\n",
    "\n",
    "sys.path.append(os.path.join(current_dir,'utilities'))\n",
    "from utilities.tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a71d3b7a-a320-46dc-a331-ea7472817a01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T06:59:23.167231Z",
     "start_time": "2024-11-01T06:59:23.162332Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from clusim.clustering import Clustering\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "import clusim.sim as sim\n",
    "\n",
    "def similarity_score(mu, graph_type, delete_type, embedding_method, percent):\n",
    "    \"\"\"Process a specific mixing parameter (mu) to do community detection.\"\"\"\n",
    "    mu_str = f\"{mu:.2f}\"\n",
    "    detected_dir = f'communitydetection_{delete_type}'\n",
    "    detected_dir = \"leiden_\" + detected_dir\n",
    "    if delete_type==\"original\":\n",
    "        raw_euclid_path = f'{detected_dir}/{graph_type}_{delete_type}_{embedding_method}_euclid_mu{mu_str}.pkl'\n",
    "    else:\n",
    "        raw_euclid_path = f'{detected_dir}_{percent}/{graph_type}_{delete_type}_{embedding_method}_euclid_mu{mu_str}.pkl'\n",
    "    with open(raw_euclid_path, 'rb') as file:\n",
    "        euclid_membership = pickle.load(file)\n",
    "    _, original_membership = load_graph(mu, graph_type, \"original\", percent)\n",
    "\n",
    "    raw_score_mu = np.zeros((len(euclid_membership),2))\n",
    "    for i in range(len(euclid_membership)):\n",
    "        raw_score_mu[i,0] = normalized_mutual_info_score(original_membership[i], euclid_membership[i], average_method='arithmetic')\n",
    "\n",
    "        euclid_membership_clus = Clustering({j: [euclid_membership[i][j]] for j in range(len(euclid_membership[i]))})\n",
    "        original_membership_clus = Clustering({j: [original_membership[i][j]] for j in range(len(original_membership[i]))})\n",
    "        \n",
    "        raw_score_mu[i,1] = sim.element_sim(original_membership_clus, euclid_membership_clus, alpha=0.9)\n",
    "\n",
    "    #print(raw_score_mu)\n",
    "\n",
    "    if delete_type==\"original\":\n",
    "        output_dir = f'leiden_results_{delete_type}'\n",
    "    else:\n",
    "        output_dir = f'leiden_results_{delete_type}_{percent}'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    raw_score_path = f'{output_dir}/{graph_type}_{delete_type}_{embedding_method}_raw_score_mu{mu_str}.pkl'\n",
    "    with open(raw_score_path, 'wb') as file:\n",
    "        pickle.dump(raw_score_mu, file)\n",
    "    # print(f\"RAW_SCORE for mu={mu_str} saved to {raw_score_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef44e903-6e94-4059-bd54-8b97a3af8c3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T06:59:23.238603Z",
     "start_time": "2024-11-01T06:59:23.234569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmu=0.05\\ngraph_type = \\'lfr\\'\\ndelete_type = \\'original\\'\\nembedding_method = \"lap\" # \"lap\" or \"n2v\"\\npercent = 0.6\\nsimilarity_score(mu, graph_type, delete_type, embedding_method, percent)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "mu=0.05\n",
    "graph_type = 'lfr'\n",
    "delete_type = 'original'\n",
    "embedding_method = \"lap\" # \"lap\" or \"n2v\"\n",
    "percent = 0.6\n",
    "similarity_score(mu, graph_type, delete_type, embedding_method, percent)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0815761-a878-4db4-b67e-7fd1e0b3bd64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T07:00:55.574072Z",
     "start_time": "2024-11-01T06:59:23.407070Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work Done for lfr, original, mu=0.05\n",
      "Work Done for lfr, original, mu=0.1\n",
      "Work Done for lfr, original, mu=0.15\n",
      "Work Done for lfr, original, mu=0.2\n",
      "Work Done for lfr, original, mu=0.25\n",
      "Work Done for lfr, original, mu=0.3\n",
      "Work Done for lfr, original, mu=0.35\n",
      "Work Done for lfr, original, mu=0.4\n",
      "Work Done for lfr, original, mu=0.45\n",
      "Work Done for lfr, original, mu=0.5\n",
      "Work Done for lfr, random, mu=0.05\n",
      "Work Done for lfr, random, mu=0.1\n",
      "Work Done for lfr, random, mu=0.15\n",
      "Work Done for lfr, random, mu=0.2\n",
      "Work Done for lfr, random, mu=0.25\n",
      "Work Done for lfr, random, mu=0.3\n",
      "Work Done for lfr, random, mu=0.35\n",
      "Work Done for lfr, random, mu=0.4\n",
      "Work Done for lfr, random, mu=0.45\n",
      "Work Done for lfr, random, mu=0.5\n",
      "Work Done for lfr, sparse, mu=0.05\n",
      "Work Done for lfr, sparse, mu=0.1\n",
      "Work Done for lfr, sparse, mu=0.15\n",
      "Work Done for lfr, sparse, mu=0.2\n",
      "Work Done for lfr, sparse, mu=0.25\n",
      "Work Done for lfr, sparse, mu=0.3\n",
      "Work Done for lfr, sparse, mu=0.35\n",
      "Work Done for lfr, sparse, mu=0.4\n",
      "Work Done for lfr, sparse, mu=0.45\n",
      "Work Done for lfr, sparse, mu=0.5\n",
      "Work Done for ppm, original, mu=0.05\n",
      "Work Done for ppm, original, mu=0.1\n",
      "Work Done for ppm, original, mu=0.15\n",
      "Work Done for ppm, original, mu=0.2\n",
      "Work Done for ppm, original, mu=0.25\n",
      "Work Done for ppm, original, mu=0.3\n",
      "Work Done for ppm, original, mu=0.35\n",
      "Work Done for ppm, original, mu=0.4\n",
      "Work Done for ppm, original, mu=0.45\n",
      "Work Done for ppm, original, mu=0.5\n",
      "Work Done for ppm, original, mu=0.55\n",
      "Work Done for ppm, original, mu=0.6\n",
      "Work Done for ppm, original, mu=0.65\n",
      "Work Done for ppm, original, mu=0.7\n",
      "Work Done for ppm, original, mu=0.75\n",
      "Work Done for ppm, original, mu=0.8\n",
      "Work Done for ppm, original, mu=0.85\n",
      "Work Done for ppm, original, mu=0.9\n",
      "Work Done for ppm, random, mu=0.05\n",
      "Work Done for ppm, random, mu=0.1\n",
      "Work Done for ppm, random, mu=0.15\n",
      "Work Done for ppm, random, mu=0.2\n",
      "Work Done for ppm, random, mu=0.25\n",
      "Work Done for ppm, random, mu=0.3\n",
      "Work Done for ppm, random, mu=0.35\n",
      "Work Done for ppm, random, mu=0.4\n",
      "Work Done for ppm, random, mu=0.45\n",
      "Work Done for ppm, random, mu=0.5\n",
      "Work Done for ppm, random, mu=0.55\n",
      "Work Done for ppm, random, mu=0.6\n",
      "Work Done for ppm, random, mu=0.65\n",
      "Work Done for ppm, random, mu=0.7\n",
      "Work Done for ppm, random, mu=0.75\n",
      "Work Done for ppm, random, mu=0.8\n",
      "Work Done for ppm, random, mu=0.85\n",
      "Work Done for ppm, random, mu=0.9\n",
      "Work Done for ppm, sparse, mu=0.05\n",
      "Work Done for ppm, sparse, mu=0.1\n",
      "Work Done for ppm, sparse, mu=0.15\n",
      "Work Done for ppm, sparse, mu=0.2\n",
      "Work Done for ppm, sparse, mu=0.25\n",
      "Work Done for ppm, sparse, mu=0.3\n",
      "Work Done for ppm, sparse, mu=0.35\n",
      "Work Done for ppm, sparse, mu=0.4\n",
      "Work Done for ppm, sparse, mu=0.45\n",
      "Work Done for ppm, sparse, mu=0.5\n",
      "Work Done for ppm, sparse, mu=0.55\n",
      "Work Done for ppm, sparse, mu=0.6\n",
      "Work Done for ppm, sparse, mu=0.65\n",
      "Work Done for ppm, sparse, mu=0.7\n",
      "Work Done for ppm, sparse, mu=0.75\n",
      "Work Done for ppm, sparse, mu=0.8\n",
      "Work Done for ppm, sparse, mu=0.85\n",
      "Work Done for ppm, sparse, mu=0.9\n"
     ]
    }
   ],
   "source": [
    "start_step = 0.05\n",
    "step_size = 0.05\n",
    "graph_type = \"ppm\"\n",
    "end_steps = {\"lfr\": 0.5, \"ppm\": 0.9}\n",
    "end_step = end_steps[graph_type]\n",
    "MU = np.around(np.arange(start_step, end_step + 0.01, step_size), decimals=2)\n",
    "percent = 0.6\n",
    "\n",
    "graph_types = ['lfr', 'ppm']\n",
    "delete_types = ['original', 'random', 'sparse']\n",
    "#delete_types = ['random', 'sparse']\n",
    "#delete_types = ['sparse']\n",
    "embedding_method = 'lap'\n",
    "\n",
    "\n",
    "for graph_type in graph_types:\n",
    "    for delete_type in delete_types:\n",
    "        end_step = end_steps[graph_type]\n",
    "        MU = np.around(np.arange(start_step, end_step + 0.01, step_size), decimals=2)\n",
    "        for mu in MU:\n",
    "            similarity_score(mu, graph_type, delete_type, embedding_method, percent)\n",
    "            print(f\"Work Done for {graph_type}, {delete_type}, mu={mu}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
